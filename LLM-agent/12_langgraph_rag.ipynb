{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c4bb01",
   "metadata": {},
   "source": [
    "# RAG w/ Langgraph\n",
    "`12_langgraph_rag.ipynb`\n",
    "\n",
    "- https://python.langchain.com/docs/tutorials/rag/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c66afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# 1. Loader (웹문서)\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer  # pip install beautifulsoup4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    # 문서 출처 URL\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/', ),\n",
    "    # 웹페이지 안에서 필요한 정보만 선택\n",
    "    bs_kwargs={\n",
    "        'parse_only': SoupStrainer(class_=['post-content']) \n",
    "    }\n",
    "    # header_template={}\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. Splitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "print(len(splitted_docs))\n",
    "\n",
    "# 3. Embedding Model\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')  # small <-> large\n",
    "\n",
    "# 4. Vectorstore (지금은 FAISS -> 클라우드-Pinecone)\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(splitted_docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "for m in prompt.messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25caa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "# State\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import TypedDict, List\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Node\n",
    "# 검색 노드\n",
    "def retrieve(state: State):\n",
    "    # [ Document * 4 ]\n",
    "    retrieved_docs = vectorstore.similarity_search(state['question'], k=4)\n",
    "\n",
    "    # 나머지 return 하지 않은 state 항목들은, 알아서 그대로 감 (question, answer 는 알아서 그대로 나감)\n",
    "    return { 'context': retrieved_docs, }\n",
    "\n",
    "\n",
    "# 답변 생성노드\n",
    "def generate(state: State):\n",
    "    # Document 객체의 필요없는 정보는 다 빼고, 내용에 해당하는 page_content 만 모아서 넘기면 토큰 절약 가능.\n",
    "    context_str = ''\n",
    "    for doc in state['context']:\n",
    "        context_str += doc.page_content + '\\n------------------------\\n'\n",
    "    \n",
    "    question_with_context = prompt.invoke({'question': state['question'], 'context': context_str})\n",
    "    response = llm.invoke(question_with_context)\n",
    "    return {'answer': response.content}\n",
    "\n",
    "# Graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node('retrieve', retrieve)\n",
    "builder.add_node('generate', generate)\n",
    "\n",
    "builder.add_edge(START, 'retrieve')\n",
    "builder.add_edge('retrieve', 'generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# 출력\n",
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d73867",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.invoke({'question': '에이전트 시스템에 대해 알려줘!'})\n",
    "\n",
    "final_state['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2978fa",
   "metadata": {},
   "source": [
    "*메세지 스트리밍*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1562413",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition? 한국어로 답해줘\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a93494",
   "metadata": {},
   "source": [
    "## RAG +a\n",
    "- Metadata 편집\n",
    "- Query 분석 - 보완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c70e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 편집\n",
    "\n",
    "# 문서 63개중 1/3 지점\n",
    "third = len(splitted_docs) // 3\n",
    "\n",
    "# metadata 에 'section' 추가중 (기능적 의미는 없음.)\n",
    "for idx, doc in enumerate(splitted_docs):\n",
    "    if idx < third:\n",
    "        doc.metadata['section'] = 'beginning'\n",
    "    elif idx < third * 2:\n",
    "        doc.metadata['section'] = 'middle'\n",
    "    else:\n",
    "        doc.metadata['section'] = 'end'\n",
    "\n",
    "vectorstore = FAISS.from_documents(splitted_docs, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ffabaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State를 더 빡빡하게 정의하기 위해, 위에 따로 정의한 클래스 Search\n",
    "\n",
    "from typing import Literal  # 말그대로\n",
    "from typing_extensions import Annotated  # 할말이 좀 더 있다\n",
    "\n",
    "\n",
    "class Search(TypedDict):  # StructuredOutput 에서 사용하기 위함.\n",
    "    \"\"\"Vectorstore Search Query\"\"\"\n",
    "    # 1. 타입, 2. ... -> NOT NULL, 3. 설명(AI용)\n",
    "    query: Annotated[str, ..., 'Search query to run']\n",
    "    section: Annotated[\n",
    "        Literal['beginning', 'middle', 'end'],\n",
    "        ..., \n",
    "        'Section to query'\n",
    "    ]\n",
    "\n",
    "\n",
    "class MyState(TypedDict):\n",
    "    question: str\n",
    "    query: Search  \n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1325b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node\n",
    "def analyze_query(state: MyState):\n",
    "    # Search 클래스에 맞춰 사용자 question 을 {query, section}로 바꿈\n",
    "    s_llm = llm.with_structured_output(Search)\n",
    "    query = s_llm.invoke(state['question'])\n",
    "    return {'query': query}\n",
    "\n",
    "def retrieve(state: MyState):\n",
    "    query = state['query']\n",
    "    docs = vectorstore.similarity_search(\n",
    "        query['query'],\n",
    "        # LLM이 판단한 section 과 실제 문서조각의 section이 맞을 경우에만 검색.\n",
    "        filter=lambda metadata: metadata.get('section') == query['section'],\n",
    "    )\n",
    "    return {'context': docs}\n",
    "\n",
    "def generate(state: MyState):\n",
    "    # Token 아끼기 위해, 내용만 추려서 문자열로 만들기\n",
    "    doc_str = ''\n",
    "    for doc in state['context']:\n",
    "        doc_str += doc.page_content + '\\n=====================\\n'\n",
    "    \n",
    "    question_with_context = prompt.invoke({'question': state['question'], 'context': doc_str})\n",
    "    res = llm.invoke(question_with_context)\n",
    "    return {'answer': res.content}\n",
    "\n",
    "\n",
    "builder = StateGraph(MyState)\n",
    "builder.add_node('analyze_query', analyze_query)\n",
    "builder.add_node('retrieve', retrieve)\n",
    "builder.add_node('generate', generate)\n",
    "\n",
    "builder.add_edge(START, 'analyze_query')\n",
    "builder.add_edge('analyze_query', 'retrieve')\n",
    "builder.add_edge('retrieve', 'generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({'question': '작업분배 뭐냐'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187e8e9",
   "metadata": {},
   "source": [
    "## 25-08-09 대화형 RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4694dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain + Pinecone\n",
    "%pip install -q langchain-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer  # pip install beautifulsoup4\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=('https://lilianweng.github.io/posts/2023-06-23-agent/', ),\n",
    "    bs_kwargs={\n",
    "        'parse_only': SoupStrainer(class_=['post-content']) \n",
    "    }\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-small')  # small <-> large\n",
    "\n",
    "index_name = 'gaida-1st'\n",
    "\n",
    "# 1회 실행하면, 실제 데이터가 들어가서 영구 저장 됨.\n",
    "# vectorstore = PineconeVectorStore.from_documents(\n",
    "#     splitted_docs, \n",
    "#     index_name=index_name, \n",
    "#     embedding=embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c354ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존에 존재하는 index를 불러오는 코드\n",
    "index_name = 'gaida-1st'\n",
    "vectorstore = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format='content_and_artifact')  # 2개를 return 한다\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query\n",
    "    Args:\n",
    "        query : Query to search\n",
    "    \"\"\"\n",
    "    # 원본 Document list (artifact)\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    # 편집한 텍스트 (content)\n",
    "    result_text = '\\n\\n'.join(\n",
    "        (f'Source: {doc.metadata}\\nContent: {doc.page_content}')\n",
    "        for doc in docs\n",
    "    )\n",
    "    return result_text, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0f3f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "# Node\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"도구 호출을 하거나, 최종 응답을 한다.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    guide = SystemMessage(\n",
    "        content=\"\"\"\n",
    "        넌 AI 어시스턴트야. 만약 사용자가 LLM이나 Agent System과 관련된 질문을 하면\n",
    "        `retrieve` Tool을 사용해야해.\n",
    "        \"\"\"\n",
    "    )\n",
    "    res = llm_with_tools.invoke([guide] + state['messages'])\n",
    "    return {'messages': [res]}\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"응답 생성\"\"\"\n",
    "    tool_messages = []\n",
    "    for msg in reversed(state['messages']):  # 메세지 목록을 뒤집음: 최신 메세지부터 순회\n",
    "        if msg.type == 'tool':\n",
    "            tool_messages.append(msg)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages.reverse()\n",
    "    docs_content = '\\n\\n'.join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    # 필요 없는 Tool 메세지들을 제외하고, AI, Human, System 메시지만 모아서 정리\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce835d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "builder = StateGraph(MessagesState) # 'messages'\n",
    "\n",
    "# builder.add_node('query_or_respond', query_or_respond)  # 아래와 같은 결과\n",
    "builder.add_node(query_or_respond)\n",
    "builder.add_node(tools)\n",
    "builder.add_node(generate)\n",
    "\n",
    "# builder.set_entry_point('query_or_respond')  # 아래와 같은 말\n",
    "builder.add_edge(START, 'query_or_respond')\n",
    "builder.add_conditional_edges(\n",
    "    'query_or_respond',\n",
    "    tools_condition,\n",
    "    {END: END, 'tools': 'tools'}  # 정확하게 상황별 다음 Node 를 지정할 수 있음\n",
    ")\n",
    "builder.add_edge('tools', 'generate')\n",
    "builder.add_edge('generate', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c12657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 그래프를 실행하려면?\n",
    "input_state = {\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'Task Decomposition 이 뭐야?'}\n",
    "    ]\n",
    "}\n",
    "res = graph.invoke(input_state)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b84edf",
   "metadata": {},
   "source": [
    "## 대화 기록 저장하기 (Langgraph Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b52973fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# 위에 정의된 builder 사용\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bd0ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LLM Agent System에 대해 알려줘\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_W3Hxp28bCQv6epW6Szn7XMHB)\n",
      " Call ID: call_W3Hxp28bCQv6epW6Szn7XMHB\n",
      "  Args:\n",
      "    query: LLM Agent System\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM Agent System은 대형 언어 모델(LLM)을 핵심 컨트롤러로 사용하는 자율 에이전트 시스템입니다. 이 시스템에서 LLM은 에이전트의 '두뇌' 역할을 하며, 계획(작업 분해, 자기 반성 및 개선), 메모리, 외부 도구와의 상호작용 등 여러 구성 요소와 함께 동작합니다. LLM Agent System은 복잡한 문제를 작은 단위로 나누어 해결하고, 과거 행동을 반성하여 결과를 개선하는 능력을 갖추고 있지만, 자연어 인터페이스의 신뢰성 문제와 출력 형식 오류 등 한계도 존재합니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LLM Agent는 어떤 경우에 만드는게 좋아?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_AevUj3hDN6FM8QZ3I9g6s8YJ)\n",
      " Call ID: call_AevUj3hDN6FM8QZ3I9g6s8YJ\n",
      "  Args:\n",
      "    query: LLM Agent를 만드는 것이 적합한 경우\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Case Studies#\n",
      "Scientific Discovery Agent#\n",
      "ChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\n",
      "\n",
      "The LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\n",
      "It is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM Agent는 복잡한 문제를 여러 단계로 나누어 해결해야 하거나, 다양한 외부 도구(예: 검색, 계산, 데이터베이스 등)와 연동해 자동화된 작업이 필요한 경우에 만드는 것이 좋습니다. 예를 들어, 과학적 연구, 소프트웨어 개발, 데이터 분석, 반복적인 업무 자동화 등에서 효과적으로 활용할 수 있습니다. 단순한 질의응답이나 짧은 텍스트 생성에는 굳이 LLM Agent를 만들 필요가 없습니다.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'configurable': {'thread_id': '123'}\n",
    "}\n",
    "\n",
    "input_state = {\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'LLM Agent는 어떤 경우에 만드는게 좋아?'}\n",
    "    ]\n",
    "}\n",
    "\n",
    "res = graph.invoke(input_state, config)\n",
    "\n",
    "for msg in res['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26905b46",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
