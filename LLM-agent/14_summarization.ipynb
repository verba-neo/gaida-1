{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea7777a",
   "metadata": {},
   "source": [
    "# 요약 (Summarization )\n",
    "`14_summarization.ipynb`\n",
    "\n",
    "매우 많은 양의 컨텍스트가 있을 경우, 어떻게 요약을 해야 할까?\n",
    "1. 프롬프트에 다 때려 박기\n",
    "2. Map-Reduce: 각 문서를 요약하고, 이것들을 다 합쳐서 최종 요약본을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d314897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e182ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query='reasoning',\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "docs = docs[:2]\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9072fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b15642",
   "metadata": {},
   "source": [
    "## 문서 때려 박기 (Stuff Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9a2e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해: \\n\\n{context}')\n",
    "])\n",
    "\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "res = chain.invoke({'context': docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc866680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the concept of building autonomous agents using large language models (LLMs) as the core controller. It outlines the components of such a system, including planning, memory, and tool use. The planning component involves task decomposition and self-reflection, while the memory component distinguishes between short-term and long-term memory, utilizing techniques like Maximum Inner Product Search (MIPS) for fast retrieval. The tool use component highlights the integration of external APIs to enhance the agent's capabilities. The article also presents case studies, such as ChemCrow for scientific discovery and Generative Agents for simulating human behavior. Challenges like finite context length, long-term planning, and the reliability of natural language interfaces are discussed. The article concludes with proof-of-concept examples like AutoGPT and GPT-Engineer, showcasing the potential and limitations of LLM-powered agents.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39898392",
   "metadata": {},
   "source": [
    "## Map - Reduce\n",
    "- 각각 나눠서 요약하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e641703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해: \\n\\n{context}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79858772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f8acc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(query='reasoning')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56c1993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86524b65",
   "metadata": {},
   "source": [
    "### Langgrpah로 문서별 요약 작업 조율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9f0132a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서를 더 작은 문서로 쪼개기\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,  # tiktoken 인코더라 토큰 기준 1000개\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33dd1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import Annotated, List, Literal, TypedDict\n",
    "\n",
    "from langchain.chains.combine_documents.reduce import acollapse_docs, split_list_of_docs\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "\n",
    "# 전체적으로 사용할 State (Reduce)\n",
    "class OverallState(TypedDict):\n",
    "    contents: List[str]                         # 입력 문서 조각의 내용들\n",
    "    summaries: Annotated[list, operator.add]    # 각 contents의 요약본 (노드들이 여러개의 요약을 반환하면, 자동으로 리스트에 합쳐짐)\n",
    "    collapsed_summaries: List[Document]         # summaries를 Document로 포장한 것들\n",
    "    final_summary: str                          # 최종 요약본\n",
    "\n",
    "\n",
    "# 개별 문서를 처리할 State (Map)\n",
    "class SummaryState(TypedDict):\n",
    "    content: str    # 각 문서를 요약할 때 사용할 문서의 내용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed05ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_MAX = 1000\n",
    "\n",
    "map_prmopt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용의 정확한 요약을 해\\n\\n{context}')\n",
    "])\n",
    "\n",
    "reduce_template = \"\"\"\n",
    "아래는 요약된 문서들이야.\n",
    "\n",
    "{docs}\n",
    "---\n",
    "이것들을 가지고 정제해서 최종 통합본을 잘 만들어줘.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([\n",
    "    ('human', reduce_template)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ddc095ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node, Router 아닌 실제 사용할 함수들\n",
    "\n",
    "async def _reduce(input: dict) -> str:\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return res.content\n",
    "\n",
    "# documents 인자 내부의 모든 내용의 토큰 총 합\n",
    "def sum_docs_tokens(documents: List[Document]) -> int:\n",
    "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge (router) -> 각 원본조각을 요약할수 있게 generate_summary 로 보냄 (문서 조각 개수만큼)\n",
    "def map_summaries(state: OverallState):\n",
    "    result = []\n",
    "    for content in state['contents']:\n",
    "        result.append(Send('generate_summary', {'content': content}))\n",
    "    return result  # List Comprehension 으로 교체 가능\n",
    "\n",
    "\n",
    "# Edge (router) -> 재귀적으로 계속 collapse_suammries 를 할지, 끝낼지 결정하는 라우터\n",
    "def should_collapse(\n",
    "    state: OverallState,\n",
    ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
    "    num_tokens = sum_docs_tokens(state[\"collapsed_summaries\"])\n",
    "    if num_tokens > TOKEN_MAX:\n",
    "        return \"collapse_summaries\"\n",
    "    else:\n",
    "        return \"generate_final_summary\"\n",
    "\n",
    "\n",
    "# Node: 주어진 내용을 요약함. (비동기적 실행)\n",
    "async def generate_summary(state: SummaryState):\n",
    "    prompt = map_prmopt.invoke({'context': state['content']})\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return {'summaries': [res.content]}\n",
    "\n",
    "\n",
    "# Node: 위에서 생성한 요약들을 Document() 객체로 만들어서 'collapsed_summaries' 키에 넣어줌\n",
    "def collect_summaries(state: OverallState):\n",
    "    return {\n",
    "        'collapsed_summaries': [Document(summary) for summary in state['summaries']]\n",
    "    }\n",
    "\n",
    "\n",
    "# Node: 1차 요약이 완료. -> 요약본이 토큰수가 너무 많을 수 있다 -> 필요에 따라 더 작은 요약으로 축소(collapse)\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    docs_lists = split_list_of_docs(\n",
    "        state['collapsed_summaries'],\n",
    "        sum_docs_tokens,\n",
    "        TOKEN_MAX\n",
    "    )\n",
    "    results = []\n",
    "    for doc_list in docs_lists:\n",
    "        results.append(await acollapse_docs(doc_list, _reduce))\n",
    "\n",
    "    return {'collapsed_summaries': results}\n",
    "\n",
    "\n",
    "# Node: 최종 정리 노드\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c348959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the graph\n",
    "# Nodes:\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\", generate_summary)  # same as before\n",
    "graph.add_node(\"collect_summaries\", collect_summaries)\n",
    "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
    "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "\n",
    "# Edges:\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
    "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
    "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
    "graph.add_edge(\"generate_final_summary\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_summary': {'summaries': ['The document outlines a set of commands and resources available for task execution, including internet searches, website browsing, GPT agent management, file operations, code analysis, and more. It emphasizes the importance of efficiency, self-evaluation, and strategic decision-making to optimize performance. The document also highlights the use of GPT-3.5 powered agents for task delegation and provides guidelines for continuous improvement and cost-effective task completion.']}}\n",
      "{'generate_summary': {'summaries': [\"The document discusses the limitations and challenges faced by LLM-powered autonomous agents. It highlights the finite context length, which restricts the inclusion of historical information and detailed instructions, impacting the system's ability to learn from past mistakes. Long-term planning and task decomposition are also challenging, as LLMs struggle to adjust plans when encountering unexpected errors. Additionally, the reliability of the natural language interface is questioned due to potential formatting errors and rebellious behavior from LLMs. The document emphasizes the need for improved mechanisms to enhance the robustness and reliability of these systems.\"]}}\n",
      "{'generate_summary': {'summaries': ['The text discusses the process of anticancer drug discovery, including selecting a target, requesting a scaffold, and attempting synthesis of identified compounds. It also highlights the risks associated with synthesizing illicit drugs and bioweapons, with a test set of known chemical weapon agents being used to evaluate synthesis attempts. The text then shifts to the concept of Generative Agents, a simulation where virtual characters interact in a sandbox environment, using LLM-powered agents with memory, planning, and reflection mechanisms to simulate human behavior. The architecture of these agents allows for emergent social behaviors and interactions. Additionally, the text mentions AutoGPT, an autonomous agent system with LLM as the main controller, highlighting its potential and limitations.']}}\n",
      "{'generate_summary': {'summaries': [\"The text discusses the process and challenges of using Large Language Models (LLMs) in real-world applications, specifically focusing on task execution and response generation. It highlights the need for efficiency and stability improvements in LLM outputs and interactions with external models. The API-Bank benchmark is introduced as a tool to evaluate LLMs' ability to use APIs effectively, with three levels of evaluation focusing on API calling, retrieval, and planning. Case studies like ChemCrow demonstrate the use of LLMs in scientific discovery, showing that while LLMs can perform well, human expertise is crucial for evaluating complex tasks accurately.\"]}}\n",
      "{'generate_summary': {'summaries': ['Human memory can be categorized into three main types: sensory memory, short-term memory (STM) or working memory, and long-term memory (LTM). Sensory memory retains impressions of sensory information for a few seconds and includes subcategories like iconic (visual), echoic (auditory), and haptic (touch) memory. Short-term memory holds information we are currently aware of for 20-30 seconds and has a capacity of about 7 items. Long-term memory stores information for a long time with unlimited capacity and includes explicit/declarative memory (facts and events) and implicit/procedural memory (skills and routines).\\n\\nIn the context of machine learning, sensory memory is likened to learning embedding representations for raw inputs, short-term memory to in-context learning with finite context window length, and long-term memory to an external vector store accessible via fast retrieval. Maximum Inner Product Search (MIPS) is used to optimize retrieval speed from external memory, often employing approximate nearest neighbors (ANN) algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN to balance speed and accuracy.']}}\n",
      "{'generate_summary': {'summaries': [\"The conversation involves a user instructing an AI assistant to create a fully functional code architecture for a game with a Model-View-Controller (MVC) pattern. The assistant is expected to outline the core classes, functions, and methods necessary for the implementation, and then provide the complete code for each file in a markdown format. The assistant makes assumptions about the game's model, view, and controller components and asks for clarification on keyboard control implementation. The user reiterates the steps for the assistant to follow, emphasizing the need for fully functional code, proper file naming conventions, and compatibility between different files. The conversation highlights the challenges of building LLM-centered agents, noting the limitations of training data up to October 2023.\"]}}\n",
      "{'generate_summary': {'summaries': ['```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The task involves creating a Super Mario game in Python using the MVC architecture, with components split into separate files and controlled via keyboard input.\",\\n        \"reasoning\": \"To effectively build the game, it\\'s important to clarify the specifics of the game design, the structure of the MVC components, and the implementation of keyboard controls.\",\\n        \"plan\": \"- Clarify game specifics like level design and character mechanics\\\\n- Understand how MVC components are organized\\\\n- Determine keyboard control details\\\\n- Move to code writing once clarifications are complete\",\\n        \"criticism\": \"I should ensure that all necessary details are clarified before proceeding to the coding phase to avoid potential misunderstandings.\",\\n        \"speak\": \"We need to clarify the specifics of the game design, MVC component structure, and keyboard controls before starting the coding process.\"\\n    },\\n    \"command\": {\\n        \"name\": \"clarify\",\\n        \"args\": {\\n            \"area\": \"MVC components structure\"\\n        }\\n    }\\n}\\n```']}}\n",
      "{'generate_summary': {'summaries': ['The text discusses the use of external tools to enhance the capabilities of Large Language Models (LLMs). It highlights the concept of tool use as a unique human trait and explores how LLMs can be equipped with external tools to extend their functionality. The MRKL system is introduced as a neuro-symbolic architecture that uses expert modules to handle specific tasks, with LLMs acting as routers. Experiments show the importance of knowing when and how to use external tools, as demonstrated by the difficulty LLMs face in solving verbal math problems. The text also mentions TALM and Toolformer, which fine-tune LLMs to use external tool APIs, and provides examples like ChatGPT Plugins and OpenAI API function calling. HuggingGPT is described as a framework that uses ChatGPT for task planning and model selection, with a detailed explanation of its four-stage process: task planning, model selection, task execution, and response summarization.']}}\n",
      "{'generate_summary': {'summaries': ['The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the concept of building autonomous agents using large language models (LLMs) as their core controllers. These agents are capable of more than just generating text; they can serve as powerful general problem solvers. The system is composed of three main components: planning, memory, and tool use. \\n\\n1. **Planning** involves breaking down large tasks into smaller subgoals and refining actions through self-reflection to improve outcomes.\\n2. **Memory** includes short-term memory for in-context learning and long-term memory for retaining and recalling information over time, often using external vector stores.\\n3. **Tool Use** allows the agent to access external APIs for information not contained within the model, such as current data or proprietary sources.\\n\\nThe article also highlights proof-of-concept examples like AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs in creating autonomous agents. Challenges and references are also discussed, emphasizing the innovative nature of this technology.']}}\n",
      "{'generate_summary': {'summaries': ['이 글은 LLM(대형 언어 모델)을 활용한 자율 에이전트에 관한 연구를 다루고 있다. 다양한 연구와 참고 문헌을 통해 LLM의 추론 능력, 문제 해결, 계획 능력, 도구 사용 능력 등을 강화하는 방법을 탐구한다. 또한, LLM의 자율적 행동과 메모리, 자기 반성 기능을 결합하여 더 나은 성능을 발휘할 수 있는 방법을 제시한다. 이 연구는 LLM의 잠재력을 극대화하기 위한 다양한 접근 방식을 소개하며, 이를 통해 LLM이 보다 복잡한 작업을 수행할 수 있도록 돕는다.']}}\n",
      "{'generate_summary': {'summaries': [\"The text discusses two main components for enhancing the performance of autonomous agents in complex tasks: Planning and Self-Reflection.\\n\\n1. **Planning**: \\n   - **Task Decomposition**: Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are used to break down complex tasks into simpler steps. CoT involves step-by-step reasoning, while ToT explores multiple reasoning paths, creating a tree structure. Task decomposition can be achieved through simple prompts, task-specific instructions, or human inputs. Another approach, LLM+P, uses an external classical planner and the Planning Domain Definition Language (PDDL) for long-horizon planning, translating problems into PDDL, generating plans, and converting them back to natural language.\\n   \\n2. **Self-Reflection**:\\n   - **ReAct**: This integrates reasoning and acting by combining task-specific actions with language space, allowing interaction with the environment and generating reasoning traces. ReAct outperforms the Act-only baseline in experiments.\\n   - **Reflexion**: This framework equips agents with dynamic memory and self-reflection to improve reasoning. It uses a reward model and a heuristic function to identify inefficient or hallucinated trajectories. Self-reflection is facilitated by showing LLM examples of failed trajectories and ideal reflections, which are stored in the agent's memory for future reference.\\n\\nBoth components aim to enhance the agent's ability to plan and learn from past actions, improving performance in knowledge-intensive and decision-making tasks.\"]}}\n",
      "{'generate_summary': {'summaries': [\"The instructions provided are for writing a comprehensive and detailed code implementation based on a given architecture. The process involves several steps to ensure that the final code is complete, functional, and adheres to best practices. Here's a concise summary of the steps involved:\\n\\n1. **Define Core Components**: Identify the core classes, functions, and methods needed for the architecture. Provide a brief comment on their purpose.\\n\\n2. **Code Implementation**: Write the complete code for each component. Ensure that every detail of the architecture is implemented as code.\\n\\n3. **File Structure**: Organize the code into files, following a language and framework-appropriate naming convention. Each file should be in markdown code block format with specific tokens replaced for filename, language, and code.\\n\\n4. **Entrypoint File**: Start with the entrypoint file and then proceed to files that are imported by it, ensuring a logical flow.\\n\\n5. **Imports and Compatibility**: Ensure all necessary imports are included, and the code in different files is compatible with each other.\\n\\n6. **Dependency Management**: Include a module dependency or package manager dependency definition file, such as `requirements.txt` for Python or `package.json` for NodeJS.\\n\\n7. **Comments and Documentation**: Add comments to describe the purpose of functions and explain complex logic. Follow best practices for code documentation.\\n\\n8. **Final Checks**: Double-check that all parts of the architecture are present and correctly implemented in the files.\\n\\n9. **Python Preferences**: Use `pytest` for testing and `dataclasses` for data handling in Python projects.\\n\\nBy following these steps, the final code should be a fully functional implementation of the given architecture, complete with all necessary components and documentation.\"]}}\n",
      "{'generate_summary': {'summaries': ['The Chain of Hindsight (CoH) method, introduced by Liu et al. in 2023, aims to enhance model outputs by presenting a sequence of past outputs with feedback, allowing the model to self-improve. Human feedback data is structured as tuples containing prompts, model completions, human ratings, and hindsight feedback, ranked by reward. The model is fine-tuned to predict the best output based on this feedback sequence, with regularization to prevent overfitting and random masking to avoid copying. The training dataset includes WebGPT comparisons and human feedback data. CoH enables models to incrementally improve outputs by following instructions.\\n\\nAlgorithm Distillation (AD), proposed by Laskin et al. in 2023, applies a similar concept to reinforcement learning (RL) by using cross-episode trajectories. It encapsulates an algorithm in a history-conditioned policy, allowing the model to learn from a sequence of improved actions. AD uses behavioral cloning over actions from source policies trained for specific tasks, aiming for a task-agnostic policy. It requires multi-episode contexts to learn an in-context RL algorithm. AD shows performance close to RL^2, despite using offline RL, and learns faster than other baselines when conditioned on partial training history.']}}\n",
      "{'collect_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='The article \"LLM Powered Autonomous Agents\" by Lilian Weng discusses the concept of building autonomous agents using large language models (LLMs) as their core controllers. These agents are capable of more than just generating text; they can serve as powerful general problem solvers. The system is composed of three main components: planning, memory, and tool use. \\n\\n1. **Planning** involves breaking down large tasks into smaller subgoals and refining actions through self-reflection to improve outcomes.\\n2. **Memory** includes short-term memory for in-context learning and long-term memory for retaining and recalling information over time, often using external vector stores.\\n3. **Tool Use** allows the agent to access external APIs for information not contained within the model, such as current data or proprietary sources.\\n\\nThe article also highlights proof-of-concept examples like AutoGPT, GPT-Engineer, and BabyAGI, which demonstrate the potential of LLMs in creating autonomous agents. Challenges and references are also discussed, emphasizing the innovative nature of this technology.'), Document(metadata={}, page_content=\"The text discusses two main components for enhancing the performance of autonomous agents in complex tasks: Planning and Self-Reflection.\\n\\n1. **Planning**: \\n   - **Task Decomposition**: Techniques like Chain of Thought (CoT) and Tree of Thoughts (ToT) are used to break down complex tasks into simpler steps. CoT involves step-by-step reasoning, while ToT explores multiple reasoning paths, creating a tree structure. Task decomposition can be achieved through simple prompts, task-specific instructions, or human inputs. Another approach, LLM+P, uses an external classical planner and the Planning Domain Definition Language (PDDL) for long-horizon planning, translating problems into PDDL, generating plans, and converting them back to natural language.\\n   \\n2. **Self-Reflection**:\\n   - **ReAct**: This integrates reasoning and acting by combining task-specific actions with language space, allowing interaction with the environment and generating reasoning traces. ReAct outperforms the Act-only baseline in experiments.\\n   - **Reflexion**: This framework equips agents with dynamic memory and self-reflection to improve reasoning. It uses a reward model and a heuristic function to identify inefficient or hallucinated trajectories. Self-reflection is facilitated by showing LLM examples of failed trajectories and ideal reflections, which are stored in the agent's memory for future reference.\\n\\nBoth components aim to enhance the agent's ability to plan and learn from past actions, improving performance in knowledge-intensive and decision-making tasks.\"), Document(metadata={}, page_content='The Chain of Hindsight (CoH) method, introduced by Liu et al. in 2023, aims to enhance model outputs by presenting a sequence of past outputs with feedback, allowing the model to self-improve. Human feedback data is structured as tuples containing prompts, model completions, human ratings, and hindsight feedback, ranked by reward. The model is fine-tuned to predict the best output based on this feedback sequence, with regularization to prevent overfitting and random masking to avoid copying. The training dataset includes WebGPT comparisons and human feedback data. CoH enables models to incrementally improve outputs by following instructions.\\n\\nAlgorithm Distillation (AD), proposed by Laskin et al. in 2023, applies a similar concept to reinforcement learning (RL) by using cross-episode trajectories. It encapsulates an algorithm in a history-conditioned policy, allowing the model to learn from a sequence of improved actions. AD uses behavioral cloning over actions from source policies trained for specific tasks, aiming for a task-agnostic policy. It requires multi-episode contexts to learn an in-context RL algorithm. AD shows performance close to RL^2, despite using offline RL, and learns faster than other baselines when conditioned on partial training history.'), Document(metadata={}, page_content='Human memory can be categorized into three main types: sensory memory, short-term memory (STM) or working memory, and long-term memory (LTM). Sensory memory retains impressions of sensory information for a few seconds and includes subcategories like iconic (visual), echoic (auditory), and haptic (touch) memory. Short-term memory holds information we are currently aware of for 20-30 seconds and has a capacity of about 7 items. Long-term memory stores information for a long time with unlimited capacity and includes explicit/declarative memory (facts and events) and implicit/procedural memory (skills and routines).\\n\\nIn the context of machine learning, sensory memory is likened to learning embedding representations for raw inputs, short-term memory to in-context learning with finite context window length, and long-term memory to an external vector store accessible via fast retrieval. Maximum Inner Product Search (MIPS) is used to optimize retrieval speed from external memory, often employing approximate nearest neighbors (ANN) algorithms like LSH, ANNOY, HNSW, FAISS, and ScaNN to balance speed and accuracy.'), Document(metadata={}, page_content='The text discusses the use of external tools to enhance the capabilities of Large Language Models (LLMs). It highlights the concept of tool use as a unique human trait and explores how LLMs can be equipped with external tools to extend their functionality. The MRKL system is introduced as a neuro-symbolic architecture that uses expert modules to handle specific tasks, with LLMs acting as routers. Experiments show the importance of knowing when and how to use external tools, as demonstrated by the difficulty LLMs face in solving verbal math problems. The text also mentions TALM and Toolformer, which fine-tune LLMs to use external tool APIs, and provides examples like ChatGPT Plugins and OpenAI API function calling. HuggingGPT is described as a framework that uses ChatGPT for task planning and model selection, with a detailed explanation of its four-stage process: task planning, model selection, task execution, and response summarization.'), Document(metadata={}, page_content=\"The text discusses the process and challenges of using Large Language Models (LLMs) in real-world applications, specifically focusing on task execution and response generation. It highlights the need for efficiency and stability improvements in LLM outputs and interactions with external models. The API-Bank benchmark is introduced as a tool to evaluate LLMs' ability to use APIs effectively, with three levels of evaluation focusing on API calling, retrieval, and planning. Case studies like ChemCrow demonstrate the use of LLMs in scientific discovery, showing that while LLMs can perform well, human expertise is crucial for evaluating complex tasks accurately.\"), Document(metadata={}, page_content='The text discusses the process of anticancer drug discovery, including selecting a target, requesting a scaffold, and attempting synthesis of identified compounds. It also highlights the risks associated with synthesizing illicit drugs and bioweapons, with a test set of known chemical weapon agents being used to evaluate synthesis attempts. The text then shifts to the concept of Generative Agents, a simulation where virtual characters interact in a sandbox environment, using LLM-powered agents with memory, planning, and reflection mechanisms to simulate human behavior. The architecture of these agents allows for emergent social behaviors and interactions. Additionally, the text mentions AutoGPT, an autonomous agent system with LLM as the main controller, highlighting its potential and limitations.'), Document(metadata={}, page_content='The document outlines a set of commands and resources available for task execution, including internet searches, website browsing, GPT agent management, file operations, code analysis, and more. It emphasizes the importance of efficiency, self-evaluation, and strategic decision-making to optimize performance. The document also highlights the use of GPT-3.5 powered agents for task delegation and provides guidelines for continuous improvement and cost-effective task completion.'), Document(metadata={}, page_content='```json\\n{\\n    \"thoughts\": {\\n        \"text\": \"The task involves creating a Super Mario game in Python using the MVC architecture, with components split into separate files and controlled via keyboard input.\",\\n        \"reasoning\": \"To effectively build the game, it\\'s important to clarify the specifics of the game design, the structure of the MVC components, and the implementation of keyboard controls.\",\\n        \"plan\": \"- Clarify game specifics like level design and character mechanics\\\\n- Understand how MVC components are organized\\\\n- Determine keyboard control details\\\\n- Move to code writing once clarifications are complete\",\\n        \"criticism\": \"I should ensure that all necessary details are clarified before proceeding to the coding phase to avoid potential misunderstandings.\",\\n        \"speak\": \"We need to clarify the specifics of the game design, MVC component structure, and keyboard controls before starting the coding process.\"\\n    },\\n    \"command\": {\\n        \"name\": \"clarify\",\\n        \"args\": {\\n            \"area\": \"MVC components structure\"\\n        }\\n    }\\n}\\n```'), Document(metadata={}, page_content=\"The instructions provided are for writing a comprehensive and detailed code implementation based on a given architecture. The process involves several steps to ensure that the final code is complete, functional, and adheres to best practices. Here's a concise summary of the steps involved:\\n\\n1. **Define Core Components**: Identify the core classes, functions, and methods needed for the architecture. Provide a brief comment on their purpose.\\n\\n2. **Code Implementation**: Write the complete code for each component. Ensure that every detail of the architecture is implemented as code.\\n\\n3. **File Structure**: Organize the code into files, following a language and framework-appropriate naming convention. Each file should be in markdown code block format with specific tokens replaced for filename, language, and code.\\n\\n4. **Entrypoint File**: Start with the entrypoint file and then proceed to files that are imported by it, ensuring a logical flow.\\n\\n5. **Imports and Compatibility**: Ensure all necessary imports are included, and the code in different files is compatible with each other.\\n\\n6. **Dependency Management**: Include a module dependency or package manager dependency definition file, such as `requirements.txt` for Python or `package.json` for NodeJS.\\n\\n7. **Comments and Documentation**: Add comments to describe the purpose of functions and explain complex logic. Follow best practices for code documentation.\\n\\n8. **Final Checks**: Double-check that all parts of the architecture are present and correctly implemented in the files.\\n\\n9. **Python Preferences**: Use `pytest` for testing and `dataclasses` for data handling in Python projects.\\n\\nBy following these steps, the final code should be a fully functional implementation of the given architecture, complete with all necessary components and documentation.\"), Document(metadata={}, page_content=\"The conversation involves a user instructing an AI assistant to create a fully functional code architecture for a game with a Model-View-Controller (MVC) pattern. The assistant is expected to outline the core classes, functions, and methods necessary for the implementation, and then provide the complete code for each file in a markdown format. The assistant makes assumptions about the game's model, view, and controller components and asks for clarification on keyboard control implementation. The user reiterates the steps for the assistant to follow, emphasizing the need for fully functional code, proper file naming conventions, and compatibility between different files. The conversation highlights the challenges of building LLM-centered agents, noting the limitations of training data up to October 2023.\"), Document(metadata={}, page_content=\"The document discusses the limitations and challenges faced by LLM-powered autonomous agents. It highlights the finite context length, which restricts the inclusion of historical information and detailed instructions, impacting the system's ability to learn from past mistakes. Long-term planning and task decomposition are also challenging, as LLMs struggle to adjust plans when encountering unexpected errors. Additionally, the reliability of the natural language interface is questioned due to potential formatting errors and rebellious behavior from LLMs. The document emphasizes the need for improved mechanisms to enhance the robustness and reliability of these systems.\"), Document(metadata={}, page_content='이 글은 LLM(대형 언어 모델)을 활용한 자율 에이전트에 관한 연구를 다루고 있다. 다양한 연구와 참고 문헌을 통해 LLM의 추론 능력, 문제 해결, 계획 능력, 도구 사용 능력 등을 강화하는 방법을 탐구한다. 또한, LLM의 자율적 행동과 메모리, 자기 반성 기능을 결합하여 더 나은 성능을 발휘할 수 있는 방법을 제시한다. 이 연구는 LLM의 잠재력을 극대화하기 위한 다양한 접근 방식을 소개하며, 이를 통해 LLM이 보다 복잡한 작업을 수행할 수 있도록 돕는다.')]}}\n",
      "{'collapse_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='다음은 제공된 문서들을 기반으로 한 최종 통합본입니다:\\n\\n---\\n\\n**LLM 기반 자율 에이전트**\\n\\nLilian Weng의 \"LLM Powered Autonomous Agents\"는 대형 언어 모델(LLM)을 핵심 컨트롤러로 사용하여 자율 에이전트를 구축하는 개념을 다룹니다. 이러한 에이전트는 단순한 텍스트 생성 이상의 기능을 수행할 수 있으며, 강력한 일반 문제 해결자로서의 역할을 합니다. 시스템은 주로 계획, 메모리, 도구 사용의 세 가지 주요 구성 요소로 이루어져 있습니다.\\n\\n1. **계획(Planning)**: \\n   - **작업 분해(Task Decomposition)**: 복잡한 작업을 더 간단한 단계로 나누기 위해 Chain of Thought(CoT)와 Tree of Thoughts(ToT)와 같은 기법을 사용합니다. CoT는 단계별 추론을, ToT는 여러 추론 경로를 탐색하여 트리 구조를 만듭니다. LLM+P는 외부 고전 계획자와 계획 도메인 정의 언어(PDDL)를 사용하여 장기 계획을 수행합니다.\\n   - **자기 반성(Self-Reflection)**: ReAct와 Reflexion 프레임워크를 통해 에이전트가 환경과 상호작용하고 추론 흔적을 생성하며, 비효율적이거나 환각된 경로를 식별하여 성능을 향상시킵니다.\\n\\n2. **메모리(Memory)**: \\n   - 단기 메모리는 맥락 내 학습을 위한 것이며, 장기 메모리는 외부 벡터 저장소를 사용하여 정보를 장기간 보유하고 회상하는 데 사용됩니다. 이는 인간의 감각 기억, 단기 기억, 장기 기억과 유사하게 작동합니다.\\n\\n3. **도구 사용(Tool Use)**: \\n   - 에이전트가 모델에 포함되지 않은 현재 데이터나 독점 소스와 같은 외부 API에 접근할 수 있도록 합니다.\\n\\n**모델 개선 기법**\\n\\n- **Hindsight의 연쇄(Chain of Hindsight, CoH)**: 과거 출력과 피드백을 통해 모델이 스스로 개선할 수 있도록 하는 방법입니다. 인간 피드백 데이터를 사용하여 모델이 최상의 출력을 예측하도록 미세 조정합니다.\\n- **알고리즘 증류(Algorithm Distillation, AD)**: 강화 학습(RL)에서 교차 에피소드 경로를 사용하여 행동 복제를 통해 작업에 구애받지 않는 정책을 학습합니다.\\n\\n이러한 기술들은 LLM을 활용한 자율 에이전트의 잠재력을 보여주는 AutoGPT, GPT-Engineer, BabyAGI와 같은 개념 증명 예시를 통해 강조됩니다. 이 기술의 혁신적인 성격을 강조하며, 관련 도전 과제와 참고 문헌도 논의됩니다.'), Document(metadata={}, page_content='이 문서들은 다양한 주제를 다루고 있으며, 주로 대형 언어 모델(LLM)의 활용과 관련된 내용입니다. 다음은 이 문서들을 통합하여 정리한 내용입니다:\\n\\n1. **LLM과 외부 도구의 통합**: LLM의 기능을 확장하기 위해 외부 도구를 사용하는 방법이 논의됩니다. MRKL 시스템은 전문가 모듈을 사용하여 특정 작업을 처리하는 신경-상징적 아키텍처로 소개되며, LLM은 라우터 역할을 합니다. TALM과 Toolformer는 외부 도구 API를 사용하도록 LLM을 미세 조정하는 예시로 언급됩니다. HuggingGPT는 ChatGPT를 사용하여 작업 계획 및 모델 선택을 수행하는 프레임워크로, 네 단계의 프로세스를 통해 작업을 수행합니다.\\n\\n2. **LLM의 실세계 응용**: LLM을 실세계 응용에 사용하는 과정과 도전 과제가 강조됩니다. API-Bank 벤치마크는 LLM의 API 사용 능력을 평가하는 도구로 소개되며, ChemCrow와 같은 사례 연구는 과학적 발견에서 LLM의 사용을 보여줍니다. 복잡한 작업의 정확한 평가에는 여전히 인간의 전문성이 필요합니다.\\n\\n3. **약물 발견 및 생성 에이전트**: 항암제 발견 과정과 불법 약물 및 생화학 무기 합성의 위험이 논의됩니다. 생성 에이전트는 가상 캐릭터가 샌드박스 환경에서 상호작용하는 시뮬레이션으로, LLM 기반 에이전트가 메모리, 계획, 반성 메커니즘을 사용하여 인간 행동을 시뮬레이션합니다. AutoGPT는 LLM을 주요 컨트롤러로 사용하는 자율 에이전트 시스템으로, 그 잠재력과 한계가 강조됩니다.\\n\\n4. **작업 실행을 위한 명령 및 리소스**: 인터넷 검색, 웹사이트 탐색, GPT 에이전트 관리, 파일 작업, 코드 분석 등을 포함한 작업 실행을 위한 명령과 리소스가 설명됩니다. 효율성, 자기 평가, 전략적 의사 결정의 중요성이 강조되며, GPT-3.5 기반 에이전트를 사용한 작업 위임과 지속적인 개선 및 비용 효율적인 작업 완료를 위한 지침이 제공됩니다.\\n\\n5. **슈퍼 마리오 게임 개발 계획**: Python을 사용하여 MVC 아키텍처로 슈퍼 마리오 게임을 개발하는 계획이 제시됩니다. 게임 디자인, MVC 구성 요소 구조, 키보드 제어의 세부 사항을 명확히 한 후 코딩을 시작해야 한다는 점이 강조됩니다.\\n\\n이 통합본은 LLM의 다양한 활용 가능성과 그에 따른 도전 과제를 포괄적으로 다루고 있습니다.'), Document(metadata={}, page_content='아래는 제공된 문서들을 기반으로 한 최종 통합본입니다:\\n\\n---\\n\\n이 문서는 LLM(대형 언어 모델)을 활용한 자율 에이전트의 개발 및 구현에 관한 내용을 다룹니다. LLM을 기반으로 한 시스템은 다양한 도전과제를 가지고 있으며, 이를 극복하기 위한 여러 접근 방식을 탐구합니다.\\n\\n### 코드 구현 지침\\n\\nLLM을 활용한 시스템 개발 시, 다음과 같은 단계에 따라 코드를 구현할 수 있습니다:\\n\\n1. **핵심 구성 요소 정의**: 아키텍처에 필요한 핵심 클래스, 함수, 메서드를 식별하고, 각 요소의 목적을 간단히 설명합니다.\\n   \\n2. **코드 구현**: 각 구성 요소에 대한 완전한 코드를 작성합니다. 아키텍처의 모든 세부 사항이 코드로 구현되었는지 확인합니다.\\n\\n3. **파일 구조**: 코드 파일을 적절한 명명 규칙에 따라 조직합니다. 각 파일은 마크다운 코드 블록 형식으로 작성되며, 파일명, 언어, 코드에 대한 특정 토큰이 교체됩니다.\\n\\n4. **엔트리포인트 파일**: 엔트리포인트 파일부터 시작하여 논리적인 흐름에 따라 다른 파일들을 작성합니다.\\n\\n5. **임포트 및 호환성**: 필요한 모든 임포트를 포함하고, 서로 다른 파일의 코드가 호환되는지 확인합니다.\\n\\n6. **의존성 관리**: `requirements.txt`(Python) 또는 `package.json`(NodeJS)과 같은 모듈 또는 패키지 관리자 의존성 정의 파일을 포함합니다.\\n\\n7. **주석 및 문서화**: 함수의 목적을 설명하고 복잡한 로직을 설명하는 주석을 추가합니다. 코드 문서화에 대한 모범 사례를 따릅니다.\\n\\n8. **최종 점검**: 아키텍처의 모든 부분이 파일에 올바르게 구현되었는지 이중 확인합니다.\\n\\n9. **Python 선호사항**: Python 프로젝트에서는 `pytest`를 테스트에 사용하고, `dataclasses`를 데이터 처리에 사용합니다.\\n\\n### LLM 기반 자율 에이전트의 도전과제\\n\\nLLM 기반 자율 에이전트는 다음과 같은 도전과제를 가지고 있습니다:\\n\\n- **유한한 컨텍스트 길이**: 과거 정보와 세부 지침을 포함하는 데 제한이 있어, 과거 실수로부터 학습하는 데 어려움이 있습니다.\\n- **장기 계획 및 작업 분해**: 예기치 않은 오류 발생 시 계획을 조정하는 데 어려움을 겪습니다.\\n- **자연어 인터페이스의 신뢰성**: 포맷 오류 및 LLM의 예측 불가능한 행동으로 인해 신뢰성이 떨어질 수 있습니다.\\n\\n이러한 도전과제를 극복하기 위해, LLM의 추론 능력, 문제 해결, 계획 능력, 도구 사용 능력을 강화하는 방법을 연구합니다. 또한, 자율적 행동과 메모리, 자기 반성 기능을 결합하여 더 나은 성능을 발휘할 수 있는 방법을 제시합니다.\\n\\n이 연구는 LLM의 잠재력을 극대화하기 위한 다양한 접근 방식을 소개하며, 이를 통해 LLM이 보다 복잡한 작업을 수행할 수 있도록 돕습니다.')]}}\n"
     ]
    }
   ],
   "source": [
    "async for step in app.astream(\n",
    "    {'contents': [doc.page_content for doc in split_docs]},\n",
    "    {'recursion_limit': 10}\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9e4dd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deb0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
