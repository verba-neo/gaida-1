{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9dbb38",
   "metadata": {},
   "source": [
    "# Memory (대화 내용 기억)\n",
    "`04_memory.ipynb`\n",
    "- 대화 내용 기억\n",
    "- LLM은 기본적으로 대화 내용을 기억하지 않는다(stateless)\n",
    "- 이전 대화내용을 계속 프롬프트에 주입해야 함\n",
    "\n",
    "1. Short-Term Memory\n",
    "    - 단기기억: 한 대화 세션에 대한 기억\n",
    "2. Long-Term Memory\n",
    "    - 장기기억: 전체 세션에서 추출한 중요한 정보\n",
    "\n",
    "## Memory 구동 방식\n",
    "1. 메모리는 기본적으로 모든 대화 내역을 LLM Input에 밀어 넣는것.\n",
    "2. 이때 대화가 길어지면 토큰수 증가 및 성능 하락이 일어남\n",
    "3. 개선 방식 컨셉\n",
    "    1. 요약\n",
    "    2. 적정 길이에서 앞부분 자르기\n",
    "    3. 정리(특정 명사들로 정리, Node-Edge 그래프 방식 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8ab0a",
   "metadata": {},
   "source": [
    "## `ConversationBufferMemory`\n",
    "- 메시지 저장 -> 변수에서 추출 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', '넌 유용한 챗봇이야'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),  # 기존 채팅 내역을 다 주입\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n",
    "\n",
    "# 메모리를 저장할 변수는 {}다. 기존에 대화내용이 있다면 불러와라\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c66d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "# `chat_history`변수에, load_memory_var 결과를 저장하고, `chat_history 키를 추출`\n",
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) |\n",
    "    itemgetter('chat_history')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = chain.invoke({'input': '만나서 반가워'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    {'human': '만나서 반가워'},\n",
    "    {'ai': res.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d073f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_message = '내 이름 뭐라고?'\n",
    "res = chain.invoke({'input': my_message})\n",
    "memory.save_context(\n",
    "    {'human': my_message},\n",
    "    {'ai': res.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ffe887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인간:  \n",
      "AI:  content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CBFF9nJXUg8JJ6Iw4PGvJofRE8biz', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--0b06800f-6711-466b-bc9a-2898a2404b6b-0' usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "인간:  안녕\n",
      "AI:  content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CBFFLeYQH3NRfEvoOuqGwfgw040tG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8bb4f8d3-c863-48e8-acd7-c92ce8a03e20-0' usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "인간:  반가워\n",
      "AI:  content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CBFFPK5S5T5etvjRWtkurPef5WVcC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--549ef6f0-a520-40ab-b993-f37b758d1f65-0' usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "인간:  \n",
      "AI:  content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CBFFSveiZ5SH7xW6hP8JxviwAq4ho', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--3ddbca1d-d7be-47ba-ac7f-6602642b4732-0' usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "인간:  정지\n",
      "AI:  content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CBFFXeWxWupvULn0n0B7Rrg5Dsx7t', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--20c37d6d-eb6a-4ec4-b7c1-9c7f9eca95d2-0' usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from operator import itemgetter\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano', temperature=0)\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('system', '넌 유용한 챗봇이야'),\n",
    "        MessagesPlaceholder(variable_name='chat_history'),  # 기존 채팅 내역을 다 주입\n",
    "        ('human', '{input}'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')\n",
    "\n",
    "# `chat_history`변수에, load_memory_var 결과를 저장하고, `chat_history 키를 추출`\n",
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) |\n",
    "    itemgetter('chat_history')\n",
    ")\n",
    "\n",
    "chain = runnable | prompt | llm \n",
    "\n",
    "# 아래에 실제 gpt랑 대화하는 모습으로 만들기\n",
    "\n",
    "\n",
    "input_msg = ''\n",
    "\n",
    "# 사용자가 ('quit', '정지', '그만') 중에 하나를 입력하면 대화 종료\n",
    "while input_msg not in ('quit', '정지', '그만'):\n",
    "    input_msg = input()\n",
    "    # 대화 로직 + 대화내역 아래 출력\n",
    "    print('인간: ', input_msg)\n",
    "    print('AI: ', 'AI의 답변 메시지')\n",
    "    time.sleep(0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
