{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946d2707",
   "metadata": {},
   "source": [
    "# Tavily Web Search\n",
    "- LLM에게 웹검색을 쥐어주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435e42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langchain-tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33184e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch   \n",
    "\n",
    "search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic=\"general\",\n",
    "    search_depth=\"basic\",\n",
    "    # time_range=\"day\",\n",
    "    # include_domains=None,\n",
    "    # exclude_domains=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(search_tool.invoke({'query': '강남 신세계에서 밥먹을만한 곳 알려줘'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ad145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['query', 'search_results'],\n",
    "    template=\"\"\"넌 웹 검색결과를 요약해서 사용자의 질문에 맞게 좋은 답을 해주는 챗봇이야.\n",
    "\n",
    "    질문: {query}\n",
    "    검색결과: {search_results}\n",
    "    질문에 맞는 답을 검색결과 바탕으로 간단하게 알려줘\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'query': RunnablePassthrough(),  # 사용자 입력 그대로 이 자리에 들어옴\n",
    "        'search_results': search_tool | RunnableLambda(\n",
    "            lambda x: '\\n'.join(\n",
    "                [f'-{r['title']} ({r['content']})' for r in x['results']]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke('강남 신세계에서 점심 먹기 좋은곳')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b96bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "dumb_chain.invoke({'query': '강남 신세계에서 점심먹기 좋은곳', 'search_results': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%D')\n",
    "\n",
    "search_tool = TavilySearch(\n",
    "    max_results=5,\n",
    "    topic='general'\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', f'너는 훌륭한 어시스턴트야. 반드시 웹 검색도구를 사용해서 정보를 얻어. 최대한 답을 잘 해보자. 오늘은 {today}야.'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('human', '{input}'),\n",
    "    MessagesPlaceholder(variable_name='agent_scratchpad')  # 도구(검색) 호출때 필요함\n",
    "])\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key='chat_history'\n",
    ")\n",
    "\n",
    "agent = create_openai_tools_agent(\n",
    "    llm=llm,\n",
    "    tools=[search_tool],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, memory=memory, tools=[search_tool], verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acd4efe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m반갑습니다, 유태영님! 어떤 메뉴의 레시피를 찾고 싶으신지 알려주시면 바로 도와드리겠습니다. 3번째 메뉴가 어떤 것인지 구체적으로 말씀해 주세요.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '나는 유태영이야',\n",
       " 'chat_history': [HumanMessage(content='방금말한 메뉴중에 3번째 메뉴 레시피 찾아서 알려줘', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='물론입니다. \"3번째 메뉴\"가 어떤 메뉴인지 구체적으로 알려주시면, 해당 메뉴의 레시피를 찾아드리겠습니다. 메뉴명을 알려주시겠어요?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='나는 유태영이야', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='반갑습니다, 유태영님! 어떤 메뉴의 레시피를 찾고 싶으신지 알려주시면 바로 도와드리겠습니다. 3번째 메뉴가 어떤 것인지 구체적으로 말씀해 주세요.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '반갑습니다, 유태영님! 어떤 메뉴의 레시피를 찾고 싶으신지 알려주시면 바로 도와드리겠습니다. 3번째 메뉴가 어떤 것인지 구체적으로 말씀해 주세요.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({'input': '나는 유태영이야'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
