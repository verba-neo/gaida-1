{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91311315",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "`01_langchain_intro.ipynb`\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97edc2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc48c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAoKSzz7LrScQeMOjR8hbenxQTJyT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--325aedef-6e30-4f7a-bd93-337ef1896eaa-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19087e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면 한국어로 번역을 해주는 AI 를 만들고 싶다면?\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572d386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mangiamo il pranzo. Cosa vorresti mangiare?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 52, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAoe1JjFHfMV3vkQql03ftzBIsYWO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--05c5d59d-1178-456f-a791-c1b7be02ef2b-0', usage_metadata={'input_tokens': 52, 'output_tokens': 16, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='한국어를 이탈리어로 번역해줘'),\n",
    "    HumanMessage(content='점심을 먹자. 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Essere pieno', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 34, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqGZKEqIYmer29beWobeWzGASXBR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a0fa64d-d940-44eb-a617-d978e0bbdb56-0', usage_metadata={'input_tokens': 34, 'output_tokens': 4, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': '한국어를 이탈리어로 번역해줘'},\n",
    "    {'role': 'human', 'content': '배부르다'},\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "|S|ono| pien|o|.||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd2a0e",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법 \n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(LCEL-LanChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01205265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司を食べたいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 30, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqviCTVYVpNn6RTB1jH8HcO5fpPO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--47edd9fe-500a-458a-a81a-8029f33b6238-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10604f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 27, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqvjlkMoCoDgTgtggex4g5YCm7DU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ba7d2c5-b502-456f-b6c1-7f926d308995-0', usage_metadata={'input_tokens': 27, 'output_tokens': 7, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454b287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# a | b | c => \n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d3b79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 수집: 2025년 전반기의 매출 데이터를 수집합니다. 데이터베이스, 엑셀 시트, ERP 시스템 등에서 필요한 정보를 추출합니다.\n",
      "2. 데이터 정제: 수집한 데이터에서 결측치나 이상치를 처리하고, 필요한 형식으로 데이터를 정리합니다.\n",
      "3. 탐색적 데이터 분석(EDA): 매출 데이터를 시각화하고 통계적으로 분석하여 전반기 동안의 매출 추이와 패턴을 파악합니다.\n",
      "4. 세부분석: 제품별, 지역별, 고객별 등 다양한 요소에 따라 매출을 세부적으로 분석합니다.\n",
      "5. 결과 도출: 분석 결과를 바탕으로 2025년 전반기의 매출 상황을 종합 평가하고, 향후 전략 수립을 위한 인사이트를 도출합니다.\n",
      "6. 시각화 및 보고: 분석 결과를 시각적으로 표현하여 보고서나 프레젠테이션 형태로 클라이언트에게 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가 입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb22c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 데이터 수집: 먼저 2025년 전반기에 대한 매출 데이터를 수집해야 합니다. 이 데이터는 회사 내부 시스템에서 얻을 수도 있고, 필요에 따라 외부 소스에서도 가져올 수 있습니다.\n",
      "\n",
      "2. 데이터 정제: 수집한 데이터를 분석하기 전에 먼저 정제해야 합니다. 이상치나 누락된 데이터를 처리하고, 필요한 형식으로 데이터를 변환해야 합니다.\n",
      "\n",
      "3. 탐색적 데이터 분석 (EDA): 이제 정제된 데이터를 사용하여 탐색적 데이터 분석을 수행해야 합니다. 이를 통해 매출의 흐름, 주요 요인 및 패턴을 파악할 수 있습니다. 시각화를 통해 데이터를 쉽게 이해할 수 있도록 도와줍니다.\n",
      "\n",
      "4. 데이터 모델링: EDA를 통해 발견한 특징을 기반으로 데이터 모델링을 수행합니다. 예를 들어, 시계열 분석을 통해 매출의 추세를 예측할 수 있습니다.\n",
      "\n",
      "5. 결과 해석: 데이터 모델링을 통해 얻은 결과를 해석하고, 이를 바탕으로 이번 2025년 전반기의 매출 분석 보고서를 작성합니다.\n",
      "\n",
      "6. 향후 전략 수립: 마지막으로, 분석 결과를 토대로 향후 전략을 수립하고, 클라이언트에게 효과적인 솔루션을 제안합니다."
     ]
    }
   ],
   "source": [
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf9421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
