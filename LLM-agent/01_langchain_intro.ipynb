{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91311315",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "`01_langchain_intro.ipynb`\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97edc2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b19cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc48c0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CArZuxPASP1yqQJHq6Wc6SJ8vhN6J', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9bccccca-be2b-4b29-b07c-9c2a459927ff-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19087e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면 한국어로 번역을 해주는 AI 를 만들고 싶다면?\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4572d386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mangiamo il pranzo. Cosa vorresti mangiare?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 52, 'total_tokens': 68, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAoe1JjFHfMV3vkQql03ftzBIsYWO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--05c5d59d-1178-456f-a791-c1b7be02ef2b-0', usage_metadata={'input_tokens': 52, 'output_tokens': 16, 'total_tokens': 68, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='한국어를 이탈리어로 번역해줘'),\n",
    "    HumanMessage(content='점심을 먹자. 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Essere pieno', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 34, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqGZKEqIYmer29beWobeWzGASXBR', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1a0fa64d-d940-44eb-a617-d978e0bbdb56-0', usage_metadata={'input_tokens': 34, 'output_tokens': 4, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': '한국어를 이탈리어로 번역해줘'},\n",
    "    {'role': 'human', 'content': '배부르다'},\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f8657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "|S|ono| pien|o|.||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd2a0e",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법 \n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(LCEL-LanChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01205265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司を食べたいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 30, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqviCTVYVpNn6RTB1jH8HcO5fpPO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--47edd9fe-500a-458a-a81a-8029f33b6238-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10604f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 27, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqvjlkMoCoDgTgtggex4g5YCm7DU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3ba7d2c5-b502-456f-b6c1-7f926d308995-0', usage_metadata={'input_tokens': 27, 'output_tokens': 7, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "454b287c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# a | b | c => \n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d3b79eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 전반기 매출 분석을 위한 단계별 EDA(탐색적 데이터 분석) 과정은 다음과 같이 나눌 수 있습니다:\n",
      "\n",
      "1. 데이터 수집 및 확인\n",
      "   - 데이터 원천 파악 (ERP, POS, CRM 등)\n",
      "   - 데이터 형식 및 구조 확인\n",
      "   - 기간(2025년 1월~6월) 데이터 추출\n",
      "2. 데이터 전처리\n",
      "   - 결측치 처리\n",
      "   - 이상치 탐지 및 처리\n",
      "   - 날짜 형식 일관성 확인\n",
      "   - 필요시 데이터 정규화 또는 표준화\n",
      "3. 기초 통계 및 요약\n",
      "   - 매출 총액, 평균, 중위값 산출\n",
      "   - 월별, 주별 매출 변화 확인\n",
      "   - 카테고리별, 지역별 매출 비중 분석\n",
      "4. 시각화 분석\n",
      "   - 시간에 따른 매출 트렌드 차트\n",
      "   - 카테고리별 매출 기여도 그래프\n",
      "   - 지역별 또는 채널별 비교 차트\n",
      "5. 상세 분석\n",
      "   - 시즌별 또는 이벤트별 매출 패턴 분석\n",
      "   - 고객세그먼트별 매출 분석\n",
      "   - 상품별 또는 서비스별 매출 기여도 분석\n",
      "6. 인사이트 도출 및 보고서 작성\n",
      "   - 주요 매출 상승 또는 하락 요인 분석\n",
      "   - 개선 가능성 및 전략 제안\n",
      "   - 향후 예측 모델의 기초 자료 준비\n",
      "7. 추가 분석 필요 시 반복\n",
      "   - 세분화 또는 심층 분석 수행\n",
      "   - 사용자가 요구하는 인사이트에 맞춘 맞춤형 분석\n",
      "\n",
      "이 단계별 계획을 기반으로 데이터를 분석하시면 2025년 전반기 매출 현황을 종합적이고 체계적으로 파악하실 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가 입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb22c782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다. 2025년 전반기(1월~6월) 매출 분석을 위한 데이터 분석 단계는 다음과 같이 나눌 수 있습니다:\n",
      "\n",
      "1. **목적 및 요구사항 파악**\n",
      "   - 분석의 목표는 무엇인지 명확히 정의 (예: 매출 추세 파악, 주요 상품/지역 분석, 성장 요인 분석 등)\n",
      "   - 분석 대상 데이터의 범위와 기간 확인\n",
      "\n",
      "2. **데이터 수집**\n",
      "   - 2025년 1월부터 6월까지의 매출 관련 데이터 수집 (판매 데이터, 거래 내역, 고객 데이터, 상품 데이터 등)\n",
      "   - 필요시 여러 시스템 또는 소스에서 데이터 통합\n",
      "\n",
      "3. **데이터 전처리**\n",
      "   - 결측치 처리, 이상치 탐지 및 수정\n",
      "   - 데이터 형식 통일 (날짜, 금액 단위 등)\n",
      "   - 필요시 데이터 정제 및 변수 생성 (예: 월별, 상품군별, 지역별 분류)\n",
      "\n",
      "4. **기술적 탐색 (EDA: 탐색적 데이터 분석)**\n",
      "   - 매출 총액 및 월별 매출 추이 분석\n",
      "   - 상품군/지역별 매출 비중 파악\n",
      "   - 고객 세그먼트별 매출 분석\n",
      "   - 시계열 트렌드 및 계절성 파악\n",
      "   - 이상치 또는 갑작스러운 변화 원인 탐색\n",
      "\n",
      "5. **심층 분석 및 인사이트 도출**\n",
      "   - 매출 상승/하락 요인 분석\n",
      "   - 신제품 또는 프로모션 효과 분석\n",
      "   - 경쟁사 또는 시장 변화와의 연관성 검토 (가능 시)\n",
      "\n",
      "6. **시각화 및 보고서 작성**\n",
      "   - 분석 결과를 직관적으로 이해할 수 있는 그래프 및 차트 제작\n",
      "   - 핵심 인사이트와 추천사항 도출\n",
      "\n",
      "7. **결론 도출 및 의사결정 지원**\n",
      "   - 분석 요약 및 핵심 시사점 정리\n",
      "   - 향후 전략 수립 및 실행 방안 제시\n",
      "\n",
      "이 단계들을 차례대로 수행하면 2025년 전반기 매출 현황과 원인 분석이 체계적으로 이루어질 수 있습니다."
     ]
    }
   ],
   "source": [
    "# chain 은 Runnable 객체이기 때문에 invoke, stream, batch 메서드 사용가능\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3dcf9421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어처리(NLP) 응용 프로그램을 개발할 때 사용되는 파이썬 라이브러리로, 대형 언어 모델을 쉽게 통합하고 관리할 수 있게 도와줍니다. 이 라이브러리는 다양한 데이터 소스와 인터페이스를 연결하며, 사용자 쿼리에 맞춘 효율적인 정보 검색과 생성 기능을 지원합니다. 또한, 언어 모델과 외부 도구를 결합하여 복잡한 워크플로우를 구축하는 데 유용합니다.',\n",
       " 'Langsmith는 자연어 처리(NLP) 기술을 활용한 대화형 인공지능 플랫폼입니다. 사용자와 자연스럽게 소통하며 다양한 질문에 답하거나 정보를 제공하는 기능을 갖추고 있습니다. 이를 통해 고객 지원, 콘텐츠 생성, 맞춤형 챗봇 등 다양한 분야에서 활용되고 있습니다.',\n",
       " 'LangGraph는 자연어 처리와 지식 그래프 기술을 결합한 플랫폼으로, 언어 데이터를 구조화하여 의미 있는 관계를 시각화합니다. 이를 통해 사용자는 텍스트 내의 개체와 그 관계를 쉽게 이해하고 분석할 수 있으며, 다양한 도메인에서 인사이트를 얻을 수 있습니다. 또한, LangGraph는 머신러닝과 결합하여 자연어 이해 능력을 지속적으로 향상시키는 것이 특징입니다.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'},\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
